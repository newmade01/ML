#순환신경망
- 순차 데이터, text는 순서를 가짐
- ex.시계열 데이터
- 순환되는 고리를 가짐(자기 자신에게 되돌아옴)
- 전 sample의 출력을 다시 재사용 하는 단계

###-타임스텝
- 입력을 처리할 순서

###-셀(=순환층)
- 앞의 정보를 기억하고 있는 순환층
- 활성화함수(tanh: -1 ~ 1 사이값) *시그모이드라고 불리기도함
- =>은닉상태

#타임스템으로 펼친 신경망
- 각 입력 * 가중치 * 이전 타임스텝의 은닉상태(h) = 새로운 은닉상태(h)
- 타임스텝 1,2,3....쭉 이어짐(h1, h2 , h3 ...가 사용됨)
- 가중치 w는 샘플마다 동일하게 사용됨
- 결론: 순환신경망은 타임스텝을 거쳐서 가중치를 공유해서 구해준다

#순환 신경망의 가중치(dense층과 동일)
- 입력층&순환층: 각각의 뉴런은 완전연결(Dense층과 동일)
- 순환층: 은닉상태(h)의 다시 모든 순환층으로 순환 = 완전연결

#순환 신경망의 입력
- text단어(토큰) 
- input값: 3차원 tensor (샘플, 타임스템크기 = 시퀀스길이, 하나의 text의 배열값)
- 순환층을 거치면: 3차원 -> 2차원 (샘플, 뉴런개수)

#다층 순환 신경망
- 1개 순환 신경망 출력값: 마지막 타임스텝의 은닉상태(h)
- 다층 순환 신경망 출력값: 계속 3차원 tensor풀샘플, 타임스텝, 이전층 셀의 뉴런개수)로 유지 -> 마지막 셀만 마지막 타임스텝의 은닉상태

#순환 신경망을 사용한 예측


